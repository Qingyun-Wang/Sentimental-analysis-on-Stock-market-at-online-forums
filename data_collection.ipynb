{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtweepy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authenticate to Twitter\n",
    "CONSUMER_KEY = 'YOUR_API_KEY'\n",
    "CONSUMER_SECRET = 'YOUR_API_SECRET_KEY'\n",
    "ACCESS_TOKEN = 'YOUR_ACCESS_TOKEN'\n",
    "ACCESS_TOKEN_SECRET = 'YOUR_ACCESS_TOKEN_SECRET'\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key=CONSUMER_KEY,\n",
    "    consumer_secret=CONSUMER_SECRET,\n",
    "    access_token=ACCESS_TOKEN,\n",
    "    access_token_secret=ACCESS_TOKEN_SECRET\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Define date range\n",
    "end_date = datetime.datetime.now() \n",
    "start_date = end_date - datetime.timedelta(days=7)\n",
    "\n",
    "# Search for tweets about Apple from the past week\n",
    "tweets = tweepy.Cursor(api.search, q=\"Apple\", since=start_date, until=end_date, lang=\"en\").items()\n",
    "\n",
    "# Print tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up token and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authentication\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"bOUU3GVPswoqHAeWY-WB5g\",\n",
    "    client_secret=\"65G2ItcdbqJZU9pmGBC6303fYV-QJg\",\n",
    "    user_agent=\"script:sentimental_analysis:v1.0 (by /u/Legal_Advertising127)\"\n",
    "  #  username=''\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts = subreddit.top(limit=10)\n",
    "new_posts = subreddit.new(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title -  Lad wrote a Python script to download Alexa voice recordings, he didn't expect this email.\n",
      "ID -  g53lxf\n",
      "Author -  iEslam\n",
      "URL -  https://i.redd.it/2s0dj8ob12u41.png\n",
      "Score -  12341\n",
      "Comment count -  133\n",
      "Created - 1587424299.0\n",
      "\n",
      "\n",
      "Title -  This post has:\n",
      "ID -  hoolsm\n",
      "Author -  Krukerfluk\n",
      "URL -  https://www.reddit.com/r/Python/comments/hoolsm/this_post_has/\n",
      "Score -  9237\n",
      "Comment count -  437\n",
      "Created - 1594386373.0\n",
      "\n",
      "\n",
      "Title -  I redesign the Python logo to make it more modern\n",
      "ID -  gftejm\n",
      "Author -  jessjwilliamson\n",
      "URL -  https://i.redd.it/rxezjyf4ojx41.png\n",
      "Score -  7865\n",
      "Comment count -  266\n",
      "Created - 1588945149.0\n",
      "\n",
      "\n",
      "Title -  Automate the boring stuff with python - tinder\n",
      "ID -  7kpme8\n",
      "Author -  backprop88\n",
      "URL -  https://gfycat.com/PointlessSimplisticAmericanquarterhorse\n",
      "Score -  6719\n",
      "Comment count -  328\n",
      "Created - 1513644476.0\n",
      "\n",
      "\n",
      "Title -  Just finished programming and building my own smart mirror in python, wrote all of the code myself and implemented my own voice control and facial recognition features\n",
      "ID -  dmkx8a\n",
      "Author -  janky_british_gamer\n",
      "URL -  https://i.redd.it/24ug9g82dju31.jpg\n",
      "Score -  6609\n",
      "Comment count -  469\n",
      "Created - 1571943330.0\n",
      "\n",
      "\n",
      "Title -  I'm excited to share my first published book, Introduction to Python Programming for Business and Social Science Applications -- specifically geared towards students not specifically in computer science\n",
      "ID -  irh8l0\n",
      "Author -  paulkaefer\n",
      "URL -  https://i.redd.it/ebmh8z3c8rm51.png\n",
      "Score -  6501\n",
      "Comment count -  249\n",
      "Created - 1599933196.0\n",
      "\n",
      "\n",
      "Title -  Drawing Mona Lisa with 256 circles using evolution [Github repo in comments]\n",
      "ID -  gn9add\n",
      "Author -  Itwist101\n",
      "URL -  https://v.redd.it/nyzyx7uyfwz41\n",
      "Score -  5717\n",
      "Comment count -  121\n",
      "Created - 1589972294.0\n",
      "\n",
      "\n",
      "Title -  I made a simulation using Python in which a neural network learns to race\n",
      "ID -  hqc7ol\n",
      "Author -  atqm-\n",
      "URL -  https://v.redd.it/bgmc6q20ela51\n",
      "Score -  5694\n",
      "Comment count -  212\n",
      "Created - 1594632457.0\n",
      "\n",
      "\n",
      "Title -  Thanks to everyone‚Äôs advice, my mouse drawing algorithm has gotten much better and faster!\n",
      "ID -  ghxqod\n",
      "Author -  Nekose\n",
      "URL -  https://v.redd.it/sktc30zom7y41\n",
      "Score -  5536\n",
      "Comment count -  203\n",
      "Created - 1589235279.0\n",
      "\n",
      "\n",
      "Title -  Debugging Cheat Sheet\n",
      "ID -  iehths\n",
      "Author -  HotTeenBoy\n",
      "URL -  https://i.redd.it/p1i8awsivji51.jpg\n",
      "Score -  5450\n",
      "Comment count -  112\n",
      "Created - 1598100424.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in top_posts:\n",
    "    print('Title - ', post.title)\n",
    "    print('ID - ', post.id)\n",
    "    print('Author - ', post.author)\n",
    "    print('URL - ', post.url)\n",
    "    print('Score - ', post.score)\n",
    "    print('Comment count - ', post.num_comments)\n",
    "    print(\"Created -\", post.created_utc)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title -  Looking for contributors for my open-source AI security project\n",
      "ID -  18d3rdq\n",
      "Author -  kanxx030\n",
      "URL -  https://www.reddit.com/r/Python/comments/18d3rdq/looking_for_contributors_for_my_opensource_ai/\n",
      "Score -  1\n",
      "Comment count -  0\n",
      "Created - 1701978353.0\n",
      "\n",
      "\n",
      "Title -  Pygolo 0.2.0: write Python extensions in Go!\n",
      "ID -  18d3nt3\n",
      "Author -  cavokz\n",
      "URL -  https://www.reddit.com/r/Python/comments/18d3nt3/pygolo_020_write_python_extensions_in_go/\n",
      "Score -  1\n",
      "Comment count -  0\n",
      "Created - 1701978092.0\n",
      "\n",
      "\n",
      "Title -  CPython Dynamic Dispatch Internals: What Happens When You do a + b?\n",
      "ID -  18d0axx\n",
      "Author -  abhi9u\n",
      "URL -  https://codeconfessions.substack.com/p/cpython-dynamic-dispatch-internals\n",
      "Score -  2\n",
      "Comment count -  0\n",
      "Created - 1701969063.0\n",
      "\n",
      "\n",
      "Title -  [Video] Explaining Floats Imprecision ü§ñ\n",
      "ID -  18d05dh\n",
      "Author -  JosephLovesPython\n",
      "URL -  https://www.reddit.com/r/Python/comments/18d05dh/video_explaining_floats_imprecision/\n",
      "Score -  0\n",
      "Comment count -  0\n",
      "Created - 1701968647.0\n",
      "\n",
      "\n",
      "Title -  GitHub - eholic/pandaq: An easy pandas query-string builder.\n",
      "ID -  18cwjo3\n",
      "Author -  eholic0\n",
      "URL -  https://www.reddit.com/r/Python/comments/18cwjo3/github_eholicpandaq_an_easy_pandas_querystring/\n",
      "Score -  3\n",
      "Comment count -  0\n",
      "Created - 1701958660.0\n",
      "\n",
      "\n",
      "Title -  Customer Segmentation in Python: A Practical Approach - KDnuggets\n",
      "ID -  18cttwx\n",
      "Author -  pmz\n",
      "URL -  https://www.kdnuggets.com/customer-segmentation-in-python-a-practical-approach\n",
      "Score -  0\n",
      "Comment count -  0\n",
      "Created - 1701949384.0\n",
      "\n",
      "\n",
      "Title -  Python Compiler\n",
      "ID -  18csopu\n",
      "Author -  dcryptau\n",
      "URL -  https://codingninjas.com/studio/online-compiler\n",
      "Score -  0\n",
      "Comment count -  3\n",
      "Created - 1701944646.0\n",
      "\n",
      "\n",
      "Title -  Introducing Pharaoh-Report: a report-generation framework powered by Sphinx and Jinja\n",
      "ID -  18crkc5\n",
      "Author -  pyhannes\n",
      "URL -  https://www.reddit.com/r/Python/comments/18crkc5/introducing_pharaohreport_a_reportgeneration/\n",
      "Score -  11\n",
      "Comment count -  3\n",
      "Created - 1701939616.0\n",
      "\n",
      "\n",
      "Title -  I created a no-cost* AWS infrastructure boilerplate for Python API\n",
      "ID -  18crgim\n",
      "Author -  baxiee-developer\n",
      "URL -  https://www.reddit.com/r/Python/comments/18crgim/i_created_a_nocost_aws_infrastructure_boilerplate/\n",
      "Score -  13\n",
      "Comment count -  4\n",
      "Created - 1701939095.0\n",
      "\n",
      "\n",
      "Title -  An Open Letter to the Python Software Foundation - Python Africa\n",
      "ID -  18crae8\n",
      "Author -  chub79\n",
      "URL -  https://pythonafrica.blogspot.com/2023/12/an-open-letter-to-python-software_5.html\n",
      "Score -  85\n",
      "Comment count -  50\n",
      "Created - 1701938260.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in new_posts:\n",
    "    print('Title - ', post.title)\n",
    "    print('ID - ', post.id)\n",
    "    print('Author - ', post.author)\n",
    "    print('URL - ', post.url)\n",
    "    print('Score - ', post.score)\n",
    "    print('Comment count - ', post.num_comments)\n",
    "    print(\"Created -\", post.created_utc)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the UNIX timestamp for one week ago\n",
    "one_week_ago = datetime.now() - timedelta(days=7)\n",
    "timestamp = int(one_week_ago.timestamp())\n",
    "\n",
    "\n",
    "# List of stock market-related subreddits\n",
    "subreddits = [\"stocks\", \"investing\", \"wallstreetbets\", \"StockMarket\", \"options\", \"SecurityAnalysis\", \"Daytrading\"]\n",
    "\n",
    "# Search term\n",
    "search_term = \"Apple\"\n",
    "\n",
    "# Basic rate limiting\n",
    "def rate_limited_request(subreddits, term):\n",
    "\n",
    "    data = []\n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        try:\n",
    "            for post in subreddit.search(term, time_filter=\"week\"):\n",
    "                if post.created_utc >= timestamp:  # Ensure posts are only from the last week\n",
    "\n",
    "                    # Convert the post's timestamp to the desired format (day month year)\n",
    "                    post_time = datetime.utcfromtimestamp(post.created_utc).strftime('%d %B %Y')\n",
    "                    \n",
    "                    # Add post title and body to the data list\n",
    "                    data.append([post.title + \"\\n\" + post.selftext, post_time, subreddit_name])\n",
    "                    \n",
    "                    try:\n",
    "                        post.comments.replace_more(limit=0)  # Fetch top-level comments only\n",
    "                        for comment in post.comments:\n",
    "                            comment_time = datetime.utcfromtimestamp(comment.created_utc).strftime('%d %B %Y')\n",
    "                            data.append([comment.body, comment_time, subreddit_name])\n",
    "                    except praw.exceptions.RedditAPIException as e:\n",
    "                        print(f\"Error fetching comments: {e}\")\n",
    "                        time.sleep(10)  # Sleep for 10 seconds before retrying\n",
    "        except praw.exceptions.RedditAPIException as e:\n",
    "            print(f\"Rate limit exceeded: {e}\")\n",
    "            time.sleep(10)  # Sleep for 10 seconds before retrying\n",
    "    return data\n",
    "\n",
    "\n",
    "data = rate_limited_request(subreddits, \"Apple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\"Text\", \"Date\", \"Section\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For the first time since August, Apple's marke...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;the iPhone maker‚Äôs stock price has risen over...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeeez, feels like yesterday when they hit a tr...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚Ä¶‚Äùsoars **to**‚Äù, otherwise the implication is ...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look at India‚Äôs iPhone share and get back to m...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text              Date Section\n",
       "0  For the first time since August, Apple's marke...  06 December 2023  stocks\n",
       "1  >the iPhone maker‚Äôs stock price has risen over...  06 December 2023  stocks\n",
       "2  Jeeez, feels like yesterday when they hit a tr...  06 December 2023  stocks\n",
       "3  ‚Ä¶‚Äùsoars **to**‚Äù, otherwise the implication is ...  06 December 2023  stocks\n",
       "4  Look at India‚Äôs iPhone share and get back to m...  06 December 2023  stocks"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soars otherwise implication soars\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your sample text\n",
    "text = df.iloc[3][\"Text\"]\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Get English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Filter out the stop words and non-letter tokens\n",
    "filtered_text = [word for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "# Rejoin filtered text\n",
    "filtered_sentence = ' '.join(filtered_text)\n",
    "\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚Ä¶‚Äùsoars **to**‚Äù, otherwise the implication is ‚Äúsoars by‚Äù‚Ä¶'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Function to get wordnet POS tag\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Get English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Filter out the stop words, non-letter tokens, and lemmatize\n",
    "    filtered_text = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "    # Rejoin filtered text\n",
    "    filtered_sentence = ' '.join(filtered_text)\n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Look India iPhone share get back Services fast grow segment profit raise price Apple One translate instal device grow like past year still plenty room'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(df.iloc[4][\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Look India iPhone share get back Services fast grow segment profit raise price Apple One translate instal device grow like past year still plenty room'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reddit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.read_csv('reddit_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first time since August Apple market capitaliz...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone maker stock price risen year even compa...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeeez feel like yesterday hit trillion</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soar otherwise implication soar</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look India iPhone share get back Services fast...</td>\n",
       "      <td>06 December 2023</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Fintech Apple wave goodbye Goldman Sachs credi...</td>\n",
       "      <td>05 December 2023</td>\n",
       "      <td>SecurityAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Looking advice long SQQQ HXD position Hi Every...</td>\n",
       "      <td>04 December 2023</td>\n",
       "      <td>Daytrading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>man leveraged ETFs settle daily meant held lon...</td>\n",
       "      <td>04 December 2023</td>\n",
       "      <td>Daytrading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>Looking advice long SQQQ HXD position Hi Every...</td>\n",
       "      <td>03 December 2023</td>\n",
       "      <td>Daytrading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>Looking advice long SQQQ HXD position Hi Every...</td>\n",
       "      <td>04 December 2023</td>\n",
       "      <td>Daytrading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1276 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text              Date  \\\n",
       "0     first time since August Apple market capitaliz...  06 December 2023   \n",
       "1     iPhone maker stock price risen year even compa...  06 December 2023   \n",
       "2                Jeeez feel like yesterday hit trillion  06 December 2023   \n",
       "3                       soar otherwise implication soar  06 December 2023   \n",
       "4     Look India iPhone share get back Services fast...  06 December 2023   \n",
       "...                                                 ...               ...   \n",
       "1271  Fintech Apple wave goodbye Goldman Sachs credi...  05 December 2023   \n",
       "1272  Looking advice long SQQQ HXD position Hi Every...  04 December 2023   \n",
       "1273  man leveraged ETFs settle daily meant held lon...  04 December 2023   \n",
       "1274  Looking advice long SQQQ HXD position Hi Every...  03 December 2023   \n",
       "1275  Looking advice long SQQQ HXD position Hi Every...  04 December 2023   \n",
       "\n",
       "               Section  \n",
       "0               stocks  \n",
       "1               stocks  \n",
       "2               stocks  \n",
       "3               stocks  \n",
       "4               stocks  \n",
       "...                ...  \n",
       "1271  SecurityAnalysis  \n",
       "1272        Daytrading  \n",
       "1273        Daytrading  \n",
       "1274        Daytrading  \n",
       "1275        Daytrading  \n",
       "\n",
       "[1276 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_data.csv!\n"
     ]
    }
   ],
   "source": [
    "# Calculate the UNIX timestamp for one week ago\n",
    "one_week_ago = datetime.now() - timedelta(days=7)\n",
    "timestamp = int(one_week_ago.timestamp())\n",
    "\n",
    "# List to store the data\n",
    "data = []\n",
    "\n",
    "subreddit = reddit.subreddit(\"all\")\n",
    "for post in subreddit.search(\"Apple\", time_filter=\"week\"):\n",
    "    if post.created_utc >= timestamp:  # Ensure posts are only from the last week\n",
    "\n",
    "        # Convert the post's timestamp to the desired format (day month year)\n",
    "        post_time = datetime.utcfromtimestamp(post.created_utc).strftime('%d %B %Y')\n",
    "        \n",
    "        # Add post title and body to the data list\n",
    "        data.append([post.title + \"\\n\" + post.selftext, post_time])\n",
    "        \n",
    "        post.comments.replace_more(limit=None)  # Fetch more comments\n",
    "        for comment in post.comments.list():\n",
    "            comment_time = datetime.utcfromtimestamp(comment.created_utc).strftime('%d %B %Y')\n",
    "            data.append([comment.body, comment_time])\n",
    "\n",
    "# Save data to a CSV file\n",
    "with open(\"reddit_data.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Text\", \"Date\", \"Section\"])  # Column headers\n",
    "    writer.writerows(data)  # Write the data rows\n",
    "\n",
    "print(\"Data saved to reddit_data.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('reddit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text    [The animation looks cool](https://www.apple.c...\n",
       "Date                                      24 October 2023\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple hyping speed so there‚Äôs nothing else likely to be changing I imagine.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[9]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple mouth headass\\n</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a reminder for people not to post poli...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capital gums, lower case teeth</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I know a girl who had gums like this and she g...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, mean story time. I know this girl who work...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>So then you think\\n\\n\"Phone calls are TOP TIER...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>Sorry, I didn't realise that you don't underst...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>Yeah. Because we all know tiers are only perso...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>&gt;Yeah. Because we all know tiers are only pers...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>You, too, seem unable to understand.\\n\\nI dont...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3369 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0                1\n",
       "0                                 Apple mouth headass\\n  30 October 2023\n",
       "1     This is a reminder for people not to post poli...  30 October 2023\n",
       "2                        Capital gums, lower case teeth  30 October 2023\n",
       "3     I know a girl who had gums like this and she g...  30 October 2023\n",
       "4     Ok, mean story time. I know this girl who work...  30 October 2023\n",
       "...                                                 ...              ...\n",
       "3364  So then you think\\n\\n\"Phone calls are TOP TIER...  30 October 2023\n",
       "3365  Sorry, I didn't realise that you don't underst...  30 October 2023\n",
       "3366  Yeah. Because we all know tiers are only perso...  30 October 2023\n",
       "3367  >Yeah. Because we all know tiers are only pers...  30 October 2023\n",
       "3368  You, too, seem unable to understand.\\n\\nI dont...  30 October 2023\n",
       "\n",
       "[3369 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Separate the last 20 columns and the rest\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m last_20_cols \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m other_cols \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Concatenate the lists of column names\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Separate the last 20 columns and the rest\n",
    "last_20_cols = df.columns[-1:].tolist()\n",
    "other_cols = df.columns[:-1].tolist()\n",
    "\n",
    "# Concatenate the lists of column names\n",
    "new_order = last_20_cols + other_cols\n",
    "\n",
    "# Re-index the dataframe\n",
    "df[new_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple mouth headass\\n</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a reminder for people not to post poli...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capital gums, lower case teeth</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I know a girl who had gums like this and she g...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, mean story time. I know this girl who work...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>So then you think\\n\\n\"Phone calls are TOP TIER...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>Sorry, I didn't realise that you don't underst...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>Yeah. Because we all know tiers are only perso...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>&gt;Yeah. Because we all know tiers are only pers...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>You, too, seem unable to understand.\\n\\nI dont...</td>\n",
       "      <td>30 October 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3369 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0                1\n",
       "0                                 Apple mouth headass\\n  30 October 2023\n",
       "1     This is a reminder for people not to post poli...  30 October 2023\n",
       "2                        Capital gums, lower case teeth  30 October 2023\n",
       "3     I know a girl who had gums like this and she g...  30 October 2023\n",
       "4     Ok, mean story time. I know this girl who work...  30 October 2023\n",
       "...                                                 ...              ...\n",
       "3364  So then you think\\n\\n\"Phone calls are TOP TIER...  30 October 2023\n",
       "3365  Sorry, I didn't realise that you don't underst...  30 October 2023\n",
       "3366  Yeah. Because we all know tiers are only perso...  30 October 2023\n",
       "3367  >Yeah. Because we all know tiers are only pers...  30 October 2023\n",
       "3368  You, too, seem unable to understand.\\n\\nI dont...  30 October 2023\n",
       "\n",
       "[3369 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
