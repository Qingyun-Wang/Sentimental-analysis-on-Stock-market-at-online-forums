{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtweepy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authenticate to Twitter\n",
    "CONSUMER_KEY = 'YOUR_API_KEY'\n",
    "CONSUMER_SECRET = 'YOUR_API_SECRET_KEY'\n",
    "ACCESS_TOKEN = 'YOUR_ACCESS_TOKEN'\n",
    "ACCESS_TOKEN_SECRET = 'YOUR_ACCESS_TOKEN_SECRET'\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key=CONSUMER_KEY,\n",
    "    consumer_secret=CONSUMER_SECRET,\n",
    "    access_token=ACCESS_TOKEN,\n",
    "    access_token_secret=ACCESS_TOKEN_SECRET\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Define date range\n",
    "end_date = datetime.datetime.now() \n",
    "start_date = end_date - datetime.timedelta(days=7)\n",
    "\n",
    "# Search for tweets about Apple from the past week\n",
    "tweets = tweepy.Cursor(api.search, q=\"Apple\", since=start_date, until=end_date, lang=\"en\").items()\n",
    "\n",
    "# Print tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up token and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authentication\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"bOUU3GVPswoqHAeWY-WB5g\",\n",
    "    client_secret=\"65G2ItcdbqJZU9pmGBC6303fYV-QJg\",\n",
    "    user_agent=\"script:sentimental_analysis:v1.0 (by /u/Legal_Advertising127)\"\n",
    "  #  username=''\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts = subreddit.top(limit=10)\n",
    "new_posts = subreddit.new(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title -  Lad wrote a Python script to download Alexa voice recordings, he didn't expect this email.\n",
      "ID -  g53lxf\n",
      "Author -  iEslam\n",
      "URL -  https://i.redd.it/2s0dj8ob12u41.png\n",
      "Score -  12341\n",
      "Comment count -  133\n",
      "Created - 1587424299.0\n",
      "\n",
      "\n",
      "Title -  This post has:\n",
      "ID -  hoolsm\n",
      "Author -  Krukerfluk\n",
      "URL -  https://www.reddit.com/r/Python/comments/hoolsm/this_post_has/\n",
      "Score -  9237\n",
      "Comment count -  437\n",
      "Created - 1594386373.0\n",
      "\n",
      "\n",
      "Title -  I redesign the Python logo to make it more modern\n",
      "ID -  gftejm\n",
      "Author -  jessjwilliamson\n",
      "URL -  https://i.redd.it/rxezjyf4ojx41.png\n",
      "Score -  7865\n",
      "Comment count -  266\n",
      "Created - 1588945149.0\n",
      "\n",
      "\n",
      "Title -  Automate the boring stuff with python - tinder\n",
      "ID -  7kpme8\n",
      "Author -  backprop88\n",
      "URL -  https://gfycat.com/PointlessSimplisticAmericanquarterhorse\n",
      "Score -  6719\n",
      "Comment count -  328\n",
      "Created - 1513644476.0\n",
      "\n",
      "\n",
      "Title -  Just finished programming and building my own smart mirror in python, wrote all of the code myself and implemented my own voice control and facial recognition features\n",
      "ID -  dmkx8a\n",
      "Author -  janky_british_gamer\n",
      "URL -  https://i.redd.it/24ug9g82dju31.jpg\n",
      "Score -  6609\n",
      "Comment count -  469\n",
      "Created - 1571943330.0\n",
      "\n",
      "\n",
      "Title -  I'm excited to share my first published book, Introduction to Python Programming for Business and Social Science Applications -- specifically geared towards students not specifically in computer science\n",
      "ID -  irh8l0\n",
      "Author -  paulkaefer\n",
      "URL -  https://i.redd.it/ebmh8z3c8rm51.png\n",
      "Score -  6501\n",
      "Comment count -  249\n",
      "Created - 1599933196.0\n",
      "\n",
      "\n",
      "Title -  Drawing Mona Lisa with 256 circles using evolution [Github repo in comments]\n",
      "ID -  gn9add\n",
      "Author -  Itwist101\n",
      "URL -  https://v.redd.it/nyzyx7uyfwz41\n",
      "Score -  5717\n",
      "Comment count -  121\n",
      "Created - 1589972294.0\n",
      "\n",
      "\n",
      "Title -  I made a simulation using Python in which a neural network learns to race\n",
      "ID -  hqc7ol\n",
      "Author -  atqm-\n",
      "URL -  https://v.redd.it/bgmc6q20ela51\n",
      "Score -  5694\n",
      "Comment count -  212\n",
      "Created - 1594632457.0\n",
      "\n",
      "\n",
      "Title -  Thanks to everyoneâ€™s advice, my mouse drawing algorithm has gotten much better and faster!\n",
      "ID -  ghxqod\n",
      "Author -  Nekose\n",
      "URL -  https://v.redd.it/sktc30zom7y41\n",
      "Score -  5536\n",
      "Comment count -  203\n",
      "Created - 1589235279.0\n",
      "\n",
      "\n",
      "Title -  Debugging Cheat Sheet\n",
      "ID -  iehths\n",
      "Author -  HotTeenBoy\n",
      "URL -  https://i.redd.it/p1i8awsivji51.jpg\n",
      "Score -  5450\n",
      "Comment count -  112\n",
      "Created - 1598100424.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in top_posts:\n",
    "    print('Title - ', post.title)\n",
    "    print('ID - ', post.id)\n",
    "    print('Author - ', post.author)\n",
    "    print('URL - ', post.url)\n",
    "    print('Score - ', post.score)\n",
    "    print('Comment count - ', post.num_comments)\n",
    "    print(\"Created -\", post.created_utc)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title -  Looking for contributors for my open-source AI security project\n",
      "ID -  18d3rdq\n",
      "Author -  kanxx030\n",
      "URL -  https://www.reddit.com/r/Python/comments/18d3rdq/looking_for_contributors_for_my_opensource_ai/\n",
      "Score -  1\n",
      "Comment count -  0\n",
      "Created - 1701978353.0\n",
      "\n",
      "\n",
      "Title -  Pygolo 0.2.0: write Python extensions in Go!\n",
      "ID -  18d3nt3\n",
      "Author -  cavokz\n",
      "URL -  https://www.reddit.com/r/Python/comments/18d3nt3/pygolo_020_write_python_extensions_in_go/\n",
      "Score -  1\n",
      "Comment count -  0\n",
      "Created - 1701978092.0\n",
      "\n",
      "\n",
      "Title -  CPython Dynamic Dispatch Internals: What Happens When You do a + b?\n",
      "ID -  18d0axx\n",
      "Author -  abhi9u\n",
      "URL -  https://codeconfessions.substack.com/p/cpython-dynamic-dispatch-internals\n",
      "Score -  2\n",
      "Comment count -  0\n",
      "Created - 1701969063.0\n",
      "\n",
      "\n",
      "Title -  [Video] Explaining Floats Imprecision ðŸ¤–\n",
      "ID -  18d05dh\n",
      "Author -  JosephLovesPython\n",
      "URL -  https://www.reddit.com/r/Python/comments/18d05dh/video_explaining_floats_imprecision/\n",
      "Score -  0\n",
      "Comment count -  0\n",
      "Created - 1701968647.0\n",
      "\n",
      "\n",
      "Title -  GitHub - eholic/pandaq: An easy pandas query-string builder.\n",
      "ID -  18cwjo3\n",
      "Author -  eholic0\n",
      "URL -  https://www.reddit.com/r/Python/comments/18cwjo3/github_eholicpandaq_an_easy_pandas_querystring/\n",
      "Score -  3\n",
      "Comment count -  0\n",
      "Created - 1701958660.0\n",
      "\n",
      "\n",
      "Title -  Customer Segmentation in Python: A Practical Approach - KDnuggets\n",
      "ID -  18cttwx\n",
      "Author -  pmz\n",
      "URL -  https://www.kdnuggets.com/customer-segmentation-in-python-a-practical-approach\n",
      "Score -  0\n",
      "Comment count -  0\n",
      "Created - 1701949384.0\n",
      "\n",
      "\n",
      "Title -  Python Compiler\n",
      "ID -  18csopu\n",
      "Author -  dcryptau\n",
      "URL -  https://codingninjas.com/studio/online-compiler\n",
      "Score -  0\n",
      "Comment count -  3\n",
      "Created - 1701944646.0\n",
      "\n",
      "\n",
      "Title -  Introducing Pharaoh-Report: a report-generation framework powered by Sphinx and Jinja\n",
      "ID -  18crkc5\n",
      "Author -  pyhannes\n",
      "URL -  https://www.reddit.com/r/Python/comments/18crkc5/introducing_pharaohreport_a_reportgeneration/\n",
      "Score -  11\n",
      "Comment count -  3\n",
      "Created - 1701939616.0\n",
      "\n",
      "\n",
      "Title -  I created a no-cost* AWS infrastructure boilerplate for Python API\n",
      "ID -  18crgim\n",
      "Author -  baxiee-developer\n",
      "URL -  https://www.reddit.com/r/Python/comments/18crgim/i_created_a_nocost_aws_infrastructure_boilerplate/\n",
      "Score -  13\n",
      "Comment count -  4\n",
      "Created - 1701939095.0\n",
      "\n",
      "\n",
      "Title -  An Open Letter to the Python Software Foundation - Python Africa\n",
      "ID -  18crae8\n",
      "Author -  chub79\n",
      "URL -  https://pythonafrica.blogspot.com/2023/12/an-open-letter-to-python-software_5.html\n",
      "Score -  85\n",
      "Comment count -  50\n",
      "Created - 1701938260.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in new_posts:\n",
    "    print('Title - ', post.title)\n",
    "    print('ID - ', post.id)\n",
    "    print('Author - ', post.author)\n",
    "    print('URL - ', post.url)\n",
    "    print('Score - ', post.score)\n",
    "    print('Comment count - ', post.num_comments)\n",
    "    print(\"Created -\", post.created_utc)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic rate limiting\n",
    "def rate_limited_request(subreddits, companies, effective_preriod, post_limit=100, comment_limit=20):\n",
    "    \n",
    "    data = []\n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        try:\n",
    "            for company in companies:\n",
    "                count_post=0\n",
    "                for post in subreddit.search(company, time_filter= effective_preriod):\n",
    "                    #if post.created_utc >= timestamp:  # Ensure posts are only from the last week\n",
    "\n",
    "                        # Convert the post's timestamp to the desired format (day month year)\n",
    "                        post_time = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d')\n",
    "                        \n",
    "                        # Add post title and body to the data list\n",
    "                        data.append([post.title + \"\\n\" + post.selftext, post_time, company])\n",
    "                        count_post+=1\n",
    "                        count_comment=0\n",
    "\n",
    "                        try:\n",
    "                            post.comments.replace_more(limit=0)  # Fetch top-level comments only\n",
    "                            for comment in post.comments:\n",
    "                                comment_time = datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d')\n",
    "                                data.append([comment.body, comment_time, company])\n",
    "                                count_comment+=1\n",
    "                            if count_comment > 50:\n",
    "                                break\n",
    "                        except praw.exceptions.RedditAPIException as e:\n",
    "                            print(f\"Error fetching comments: {e}\")\n",
    "                            time.sleep(10)  # Sleep for 10 seconds before retrying\n",
    "    \n",
    "                        if count_post > post_limit:\n",
    "                            break\n",
    "        except praw.exceptions.RedditAPIException as e:\n",
    "            print(f\"Rate limit exceeded: {e}\")\n",
    "            time.sleep(10)  # Sleep for 10 seconds before retrying\n",
    "    return data\n",
    "\n",
    "def collect_data_reddit(companies, effective_preriod):\n",
    "    # List of stock market-related subreddits\n",
    "    subreddits = [\"stocks\", \"investing\", \"wallstreetbets\", \"StockMarket\", \"options\", \"SecurityAnalysis\", \"Daytrading\"]\n",
    "    data = rate_limited_request(subreddits, companies, effective_preriod)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get wordnet POS tag\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Get English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Filter out the stop words, non-letter tokens, and lemmatize\n",
    "    filtered_text = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "    #filtered_text = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "\n",
    "    # Rejoin filtered text\n",
    "    filtered_sentence = ' '.join(filtered_text)\n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv_reddit(data, company):\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"Text\", \"Date\", \"Company\"])\n",
    "\n",
    "    df['Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "    df = df.groupby(['Company','Date']).agg({\"Text\": lambda x: ' '.join(x.astype(str))}).reset_index()\n",
    "\n",
    "    save_file_name = 'data/reddit_'+company+'.csv'\n",
    "\n",
    "    df.to_csv(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_company_name(text):\n",
    "    terms = ['Inc\\.', 'Corporation', 'Company', 'plc', 'Limited', ',', 'and', '\\.com', 'A/S', 'PLC', \"'s\"]\n",
    "    pattern = r'(?:' + '|'.join(terms) + ')'\n",
    "    # Replace the matched terms with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top_100_company_name(path):\n",
    "    companies_100 = pd.read_csv(path, index_col=0)\n",
    "    companies_100 = companies_100[:100]\n",
    "    companies_100['Company'] = companies_100['Company Name'].apply(clean_company_name)\n",
    "    companies = list(companies_100['Company'].values)\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = generate_top_100_company_name('data/biggest-companies-stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequests",
     "evalue": "received 429 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m collect_data_reddit(companies, \u001b[39m'\u001b[39;49m\u001b[39mmonth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb Cell 24\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollect_data_reddit\u001b[39m(companies, effective_preriod):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# List of stock market-related subreddits\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     subreddits \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mstocks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minvesting\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwallstreetbets\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStockMarket\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moptions\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSecurityAnalysis\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDaytrading\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     data \u001b[39m=\u001b[39m rate_limited_request(subreddits, companies, effective_preriod)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;32m/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m count_comment\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     post\u001b[39m.\u001b[39;49mcomments\u001b[39m.\u001b[39mreplace_more(limit\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# Fetch top-level comments only\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mfor\u001b[39;00m comment \u001b[39min\u001b[39;00m post\u001b[39m.\u001b[39mcomments:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qingyunwang/Dropbox/job/TheDataIncubator/capstone/data_collection.ipynb#Y143sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         comment_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mutcfromtimestamp(comment\u001b[39m.\u001b[39mcreated_utc)\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Dropbox/job/TheDataIncubator/capstone/venv/lib/python3.9/site-packages/praw/models/reddit/base.py:35\u001b[0m, in \u001b[0;36mRedditBase.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the value of ``attribute``.\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m attribute\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetched:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch()\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attribute)\n\u001b[1;32m     37\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m{\u001b[39;00mattribute\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m )\n",
      "File \u001b[0;32m~/Dropbox/job/TheDataIncubator/capstone/venv/lib/python3.9/site-packages/praw/models/reddit/submission.py:712\u001b[0m, in \u001b[0;36mSubmission._fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 712\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_data()\n\u001b[1;32m    713\u001b[0m     submission_listing, comment_listing \u001b[39m=\u001b[39m data\n\u001b[1;32m    714\u001b[0m     comment_listing \u001b[39m=\u001b[39m Listing(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reddit, _data\u001b[39m=\u001b[39mcomment_listing[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Dropbox/job/TheDataIncubator/capstone/venv/lib/python3.9/site-packages/praw/models/reddit/submission.py:731\u001b[0m, in \u001b[0;36mSubmission._fetch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m params\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_additional_fetch_params\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m    730\u001b[0m path \u001b[39m=\u001b[39m API_PATH[name]\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfields)\n\u001b[0;32m--> 731\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reddit\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams, path\u001b[39m=\u001b[39;49mpath)\n",
      "File \u001b[0;32m~/Dropbox/job/TheDataIncubator/capstone/venv/lib/python3.9/site-packages/praw/util/deprecate_args.py:43\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     arg_string \u001b[39m=\u001b[39m _generate_arg_string(_old_args[: \u001b[39mlen\u001b[39m(args)])\n\u001b[1;32m     37\u001b[0m     warn(\n\u001b[1;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPositional arguments for \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m will no longer be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m supported in PRAW 8.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCall this function with \u001b[39m\u001b[39m{\u001b[39;00marg_string\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(_old_args, args)), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Dropbox/job/TheDataIncubator/capstone/venv/lib/python3.9/site-packages/praw/reddit.py:941\u001b[0m, in \u001b[0;36mReddit.request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[39mraise\u001b[39;00m ClientException(\u001b[39m\"\u001b[39m\u001b[39mAt most one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    940\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_core\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    942\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    943\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    944\u001b[0m         json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    945\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    946\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    947\u001b[0m         path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    948\u001b[0m     )\n\u001b[1;32m    949\u001b[0m \u001b[39mexcept\u001b[39;00m BadRequest \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m    950\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dropbox/job/TheDataIncubator/capstone/venv/lib/python3.9/site-packages/prawcore/sessions.py:328\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m     json[\u001b[39m\"\u001b[39m\u001b[39mapi_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m url \u001b[39m=\u001b[39m urljoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requestor\u001b[39m.\u001b[39moauth_url, path)\n\u001b[0;32m--> 328\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_with_retries(\n\u001b[1;32m    329\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    330\u001b[0m     files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    331\u001b[0m     json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    332\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    333\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    334\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    335\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    336\u001b[0m )\n",
      "File \u001b[0;32m~/Dropbox/job/TheDataIncubator/capstone/venv/lib/python3.9/site-packages/prawcore/sessions.py:267\u001b[0m, in \u001b[0;36mSession._request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_retry(\n\u001b[1;32m    255\u001b[0m         data,\n\u001b[1;32m    256\u001b[0m         files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m         url,\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    266\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSTATUS_EXCEPTIONS:\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSTATUS_EXCEPTIONS[response\u001b[39m.\u001b[39mstatus_code](response)\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m codes[\u001b[39m\"\u001b[39m\u001b[39mno_content\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTooManyRequests\u001b[0m: received 429 HTTP response"
     ]
    }
   ],
   "source": [
    "data = collect_data_reddit(companies, 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv_reddit(data,\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.read_csv('reddit_company.csv', index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
